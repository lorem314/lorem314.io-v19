---
isbn: "978-1-492-07729-9"
title: "协议"
chapter: 2
---

除了向文件中读取和写入数据，或是通过**进程间通信**(Inter-Process Communication, IPC)，还有很多种和方法可以实现两个进程之间相互通信，但这些方法只能实现同一台机器上的进程之间的相互通信。

作为更为广泛的应用，进程一般需要通过网络，和其他机器(服务器)上的进程通信。这不会改变进程可以本地通信的事实，更重要的是，它可以跨网络进行数据交换。

<Tip>

亚马逊 CEO，Jeff Bezos 在 2000 年代初要求亚马逊服务必须通过网络公开 API。 这被认为是将亚马逊从一个简单的书店转变为 AWS 的云巨头的转折点。 这种模式现在为各地的科技公司所接受，允许团队以前所未有的速度访问数据和创新。

</Tip>

协议是为了能实现两端通信而被标准化过的一种格式。若通信时没有任何协议参与，信息将不可避免地错读或是不被理解。遵循行业标准总是比从头开始创建协议要好得多。最好在组织内采用较少数量的服务间协议，以减少实现工作量和 API 文档。

OSI 模型是一种用于描述网络协议的不同层级之间的关系的概念。官方的说，有七层，本章中会有一些例子，通常一个现代应用会需要多个层来描述构建。如<a href="#table_2-1">表格 2-1</a>，便于理解接下来的概念。本书主要讨论第四层，第七层，在理论上层面谈论第八层。

<Table id="2-1" title="OSI 七层模型">
  <Thead ths={["层数", "名称", "例子"]} />
  <Tbody>
    <Tr tds={["8", "用户层 (User)", "JSON, gRPC"]} />
    <Tr tds={["7", "应用层 (Application)", "HTTP, WebSocket"]} />
    <Tr tds={["6", "表示层 (Presentation)", "MIME, ASCII, TLS"]} />
    <Tr tds={["5", "会话层 (Session)", "Sockets"]} />
    <Tr tds={["4", "传输层 (Transport)", "TCP, UDP"]} />
    <Tr tds={["3", "网络层 (Network)", "IP, ICMP"]} />
    <Tr tds={["2", "数据链路层 (Data Link)", "MAC, LLC"]} />
    <Tr tds={["1", "物理层 (Physical)", "Ethernet, IEEE 802.11"]} />
  </Tbody>
</Table>

本章节注重于一些协议，被用于服务间通信的协议。我们先谈论无处不在的 HTTP 协议，和与其形影不离的 JSON 协议。也会涉及到协议的变种，如使用 TLS 来保证安全性和开启压缩。其次，GraphQL 协议，模式语法和塑造 JSON 回应的能力。最后，通过 gRPC 介绍 RPC 协议。

本章节中涉及到的例子均为同步通信，一个进程发送请求到另一个进程，然后等待另一个进程回复。不同于另一种实现方法，异步通信，进程发送请求到另一个进程后，将不会等待回复，比如把消息放到队列中。

<Section title="使用 HTTP 进行请求和响应">

第 7 层的 HTTP 协议是基于文本的协议，构建于第 4 层的 TCP 协议之上，是需要交付保证时的首选协议。该协议以一个由客户端发起的 HTTP 会话请求，和一个由服务器返回的响应为基础。该协议专门为浏览器请求网页内容而设计。多年之后，它有了很多改进。增加了语义来处理压缩、缓存、错误或是重新请求。尽管它并不是专门为 API 使用而设计的，但它无疑是网络服务之间通信的最流行的首选协议，也是构建其他协议时最流行的基础协议之一。

最后一点在本章中多次被提及。HTTP 是一种传输**超媒体**的协议，比如图像或是 HTML 文档。这包括由使用者发现和导航的内容，不一定是应用程序代码。接下来的几节将讨论这个“缺点”。

HTTP 成为面向公众的 API 使用的默认协议有很多原因。大多数公司已经拥有网站，有了可以使用 HTTP 协议的基础。浏览器经常需要使用这样的 API，但浏览器可以使用的协议却寥寥无几。有时可以通过使用浏览器 — 每个开发人员都会安装的工具 — 访问 URL 来测试 API 端点。

以下部分主要研究 HTTP 1.1 协议，该协议可以说是当今使用最流行的版本。

<Section title="HTTP 有效载荷">

HTTP 是一种基于文本的协议，允许使用任何可以通过 TCP 进行通信的系统平台或编程语言进行通信。在 NodeJS 中发送一个 HTTP 请求的代码如<a href="#code_2-1">代码 2-1</a>所示。

```js id="2-1" title="在NodeJS中发送HTTP请求"
#!/usr/bin/env node

// npm install node-fetch@2.6
const fetch = require("node-fetch")(async () => {
  const req = await fetch("http://localhost:3002/data", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "User-Agent": `nodejs/${process.version}`,
      Accept: "application/json",
    },
    body: JSON.stringify({
      foo: "bar",
    }),
  })

  const payload = await req.json()

  console.log(payload)
})()
```

若是手写 HTTP 协议的话就麻烦很多了，幸运的是，很多库帮我们处理了这些麻烦事，如命名、解析头部和请求状态行。如下展示如上代码生成的 HTTP 协议

```text id="2-2" title="HTTP请求"
POST /data HTTP/1.1             // 1
Content-Type: application/json  // 2
User-Agent: nodejs/v14.8.0
Accept: application/json
Content-Length: 13
Accept-Encoding: gzip,deflate
Connection: close
Host: localhost:3002

{"foo":"bar"}                   //3
```

1. 第一行为请求行
2. 键值对，通过冒号分隔
3. 两个换行符之后是请求体，可选

这是 http 请求的原始版本，比在浏览器中看到的典型请求简单得多，缺少诸如 cookie 和现代浏览器插入的无数默认标头之类的项目。每个换行符都表示为一个回车符和换行符的组合。响应和请求从形式上看上去差不多。如下

```http id="2-3" title="HTTP回应"
HTTP/1.1 403 Forbidden                        //1
Server: nginx/1.16.0                          //2
Date: Tue, 29 Oct 2019 15:29:31 GMT
Content-Type: application/json; charset=utf-8
Content-Length: 33
Connection: keep-alive
Cache-Control: no-cache
Vary: accept-encoding

{"error":"must_be_authenticated"}             //3
```

1. 首行是回复行
2. 头值对，通过冒号分隔
3. 隔两行，是请求体，可选

</Section>

<Section title="HTTP 语义">

HTTP 有很多重要的内置语义。正是这些语义，如果有足够的时间，任何手动协议最终都会重建。也正是这些语义和它们非常易于理解的特点，很多其他的协议最终都是基于 http 构建的。

- **HTTP 方法**

  该值是在请求行的第一个单词。在<a href="#code_2-2">代码 2-2</a>中，该值为 POST。其他的值还有，GET、PATCH 和 DELETE 等。这些方法对应着基础的创建读取更新删除操作，这些操作非常普遍，可以被应用于几乎所有的状态数据存储。遵守 http 方法的设计意图的应用程序，能让外部的观察者推断出某个具体请求的意图。

- **等幂性**

  多次执行某个操作而不会触发副作用，其中的 GET、PATCH 和 DELETE 都被视为等幂操作。如果某个上述操作所得到的结果是不确定的，例如，网络失败阻止了回应的接受，客户端再次发送同一请求是安全的。

- **状态码**

  在回应行中由三个数字表示，总共可分为 5 大类，在<a href="#code_2-3">代码 2-3</a>中，状态码是 403。<a href="#table_2-2">表格 2-2</a>展示了所有的可能值和每类所代表的意义。

  <Table id="2-2" title="HTTP 状态码">
    <Thead ths={["范围", "类型", "例子"]} />
    <Tbody>
      <Tr tds={["100-199", "消息", "101 协议切换"]} />
      <Tr tds={["200-299", "成功", "200 OK, 201 Created"]} />
      <Tr tds={["300-399", "重定向", "301 永久重定向"]} />
      <Tr tds={["400-499", "客户端错误", "401 未授权, 404 未找到"]} />
      <Tr
        tds={[
          "500-599",
          "服务端错误",
          "500 服务器内部错误, 502 上游服务器无响应",
        ]}
      />
    </Tbody>
  </Table>

<Tip>

状态码后面的文本称为**做原因短语(Reason Phrase)**。任何流行的 NodeJS HTTP 框架都会根据应用程序指定的数字状态代码来推断要使用的文本。但现代软件未使用该值，HTTP 1.1 的后续版本 HTTP/2 不提供这样的值。

</Tip>

- **客户端错误和服务端错误**

  状态码提供了一些非常有用的信息。例如，状态范围 400-499 表示客户端出错，而状态范围 500-599 则归咎于服务器。这会通知客户端，如果尝试执行操作，并且服务器确定客户端出错，则客户端不应再次尝试发送请求。如果客户端以某种方式违反协议，就会发生这种情况。但是，当发生服务器错误时，客户端应该可以随意再次尝试幂等请求。这可能是由于服务器的临时错误，例如它被请求淹没或丢失数据库连接。在<a href="../chapter-08/#幂等性和消息传递弹性">第 8 章 幂等性和消息传递弹性</a>中，您将实现自定义逻辑，以根据这些状态代码重试 HTTP 请求。

- **回应缓存**

  HTTP 还暗示了如何缓存响应。通常，唯一被缓存的响应，尤其是中间服务，是那些与 GET 请求相关联的响应。如果有与响应相关的错误代码，那么它可能不应该被缓存。更进一步，HTTP 可以设置响应应该被缓存多长时间。Expires 标头告诉客户端丢弃缓存值的特定日期和时间。不过，这个系统并不完全完美。额外的语义可以应用于缓存。例如，如果用户 #123 请求包含特定于其银行帐户的信息的文档，则很难知道缓存的结果不应该也提供给用户 #456。

- **无状态**

  HTTP 本质上是一种无状态协议。 这意味着通过发送一条消息，未来消息的含义不会改变。 这不像是一个终端会话，您可以使用 ls 列出当前目录中的文件，使用 cd 更改目录，然后发出完全相同的 ls 命令但得到不同的输出。 相反，每个请求都包含设置所需状态所需要的所有信息。

有一些通过 HTTP 模拟状态的约定。 例如，通过使用像 Cookie 这样的标头并设置唯一的会话标识符，可以在数据库中维护有关连接的状态。 除了基本的身份验证信息之外，在使用 API 时要求提供此类有状态会话令牌的客户端通常是不合适的。

</Section>

<Section title="HTTP 压缩">

可以压缩 HTTP 响应正文以减少通过网络发送的数据量。这是 HTTP 的另一个内置特性。当客户端支持压缩时，它可以选择提供 Accept-Encoding 标头。服务器在遇到标头时，可以选择使用请求中提供的任何压缩算法来压缩响应体。 gzip 压缩算法是 HTTP 压缩的普遍形式，尽管其他算法（如 brotli）可能提供更高的压缩值。响应包含一个标头，指定服务器使用的算法，例如 brotli 的 Content-Encoding: br。

压缩是网络负载大小和 CPU 使用率之间的权衡。通常，在 Node.js 服务器和任何使用数据的客户端之间的某个点支持 HTTP 压缩符合您的最大利益，尤其是当这是第三方通过 Internet 使用的流量时。但是，Node.js 并不是执行压缩的最有效工具。这是一个占用大量 CPU 的操作，应尽可能在 Node.js 进程之外处理。 <a href="../第3章#使用 HAProxy 的反向代理">使用 HAProxy 的反向代理</a>着眼于使用称为反向代理的工具来自动处理 HTTP 压缩。<a href="../第3章#SLA 和负载测试">SLA 和负载测试</a>着眼于一些基准来证明这一性能声明。

示例 2-4 演示了如何创建这样一个在进程中执行 gzip 压缩的服务器。它只使用内置的 Node.js 模块，不需要安装包。任何流行的 HTTP 框架都有自己惯用的方法来实现压缩，通常只是一个 require 和一个函数调用，但在底层它们基本上都在做同样的事情。

```js id="2-4" title="server-gzip.js"
// 源自于 https://nodejs.org/api/zlib.html
// 注意: 使用 反向代理 更有效率
const zlib = require("zlib")
const http = require("http")
const fs = require("fs")

http
  .createServer((request, response) => {
    const raw = fs.createReadStream(__dirname + "/index.html")
    const acceptEncoding = request.headers["accept-encoding"] || ""
    response.setHeader("Content-Type", "text/plain")
    console.log(acceptEncoding)
    if (acceptEncoding.includes("gzip")) {
      console.log("encoding with gzip")
      response.setHeader("Content-Encoding", "gzip")
      raw.pipe(zlib.createGzip()).pipe(response)
    } else {
      console.log("no encoding")
      raw.pipe(response)
    }
  })
  .listen(process.env.PORT || 1337)
```

现在来测试一下这个服务器。首先，创建 index.html 文件，并开启服务。

```shell
$ echo "<html><title>Hello World</title></html>" >> index.html
$ node server-gzip.js
```

接下来，在另一个命令行终端执行如下命令，观察服务器返回的结果。

```shell
# 请求未压缩过的文件
$ curl http://localhost:1337/

# 请求压缩过的文件 并查看返回的二进制
$ curl -H 'Accept-Encoding: gzip' http://localhost:1337/ | xxd

# 请求压缩过的文件 并解压缩
$ curl -H 'Accept-Encoding: gzip' http://localhost:1337/ | gunzip
```

<blockquote>
  xxd 命令可以将文件或输入转为 16 进制，或将 16 进制转还原为 2 进制形式。
</blockquote>

<blockquote>gunzip 命令用于压缩或解压缩文件。</blockquote>

这些 curl 命令充当通过网络与服务通信的客户端。 该服务打印请求是否使用压缩来帮助解释正在发生的事情。 在这个特定示例中，文件的压缩版本实际上比未压缩版本大！我们可以通过运行示例 2-5 中的两个命令来看到这种情况。

```shell id="2-5" title="比较压缩和未压缩的请求"
curl http://localhost:1337/ | wc -c
curl -H 'Accept-Encoding: gzip' http://localhost:1337/ | wc -c
```

<blockquote>
  `wc` 命令用于计算字数，由 <u>w</u>ord
  <u>c</u>ount 取首字母得来。`-c` 代表计算字节数。
</blockquote>

未压缩版本的文件大小为 40 字节，压缩版本的文件大小为 53 字节。

对于较大的文档，这不成问题。为了证明这一点，将前面的 echo 命令再运行 3 次以增加 index.html 文件的大小。然后，再次运行<a href="#code_2-5">例子 2-5</a>中的相同命令。 这次未压缩版本为 160 字节，压缩版本为 56 字节。这是因为 gzip 通过删除响应正文中的冗余来运行，并且该示例包含重复四次的相同文本。如果响应正文包含冗余文本（例如具有重复属性名称的 JSON 文档），这种冗余删除特别有用。大多数 gzip 压缩工具也可以配置为当文档小于特定大小时不启用压缩。

HTTP 压缩只压缩请求的正文。它不会影响 HTTP 标头（没有更改 Content-Length 标头中的值）。对于从服务器发送到服务器的 HTTP 请求，标头中包含着有限数量的键值对，这没什么大不了。但是，对于 Web 浏览器，发送一个包含数千字节标头的 HTTP 请求的情况并不少见（想想所有那些跟踪 cookie）。HTTP/2 的发明是为了解决这样的情况，并使用 HPACK 来压缩标头。

</Section>

<Section title="HTTPS 中的 TLS">

另一种编码形式是加密。传输层安全 (TLS) 是用于加密 HTTP 的协议。HTTP**S** 中的 S（安全）取自于 TLS 的 S。与 gzip 不同的是，TLS 也封装了 HTTP 标头。与 gzip 相同的是，TLS 是一种 CPU 密集型操作，也应该由外部进程（如反向代理）执行。TLS 取代了过时的安全套接字层 (SSL) 协议。

TLS 通过使用证书来工作。有两种类型的证书：一种包含公钥，可以安全地提供给世界上的任何人，另一种包含私钥，应该保密。这两个键本质上是配对的。任何人都可以获取消息并使用公钥对其进行加密，但只有拥有私钥的人才能解密该消息。对于 HTTP，这意味着服务器将提供其公钥，客户端将使用公钥加密请求。当客户端第一次与服务器通信时，它还会生成一个很大的随机数，本质上是会话的密码，用公钥加密并发送给服务器。此临时密码用于加密 TLS 会话。

生成证书并使用服务器启用它们可能需要一些努力来实现。传统上，它甚至是一个必须付费的昂贵功能。如今，有一项名为 Let's Encrypt 的服务不仅可以自动执行该过程，还可以使其免费。此服务的一个警告是，该工具需要将服务器公开暴露给 Internet 以验证域的 DNS 所有权。这使得加密内部服务变得困难，即使它是公共服务的明显赢家。

现在是时候动手实践一下 TLS 了。让 HTTPS 服务器在本地运行的最简单方法是生成**自签名证书**，让服务器读取该证书，然后让客户端向服务器发出请求而不执行证书验证。运行示例 2-6 中的命令生成自己的证书。随意使用喜欢的任何值，但在提示输入通用名称时使用 localhost。

```shell id="2-6" title="生成自签名证书"
mkdir -p ./{recipe-api,shared}/tls
openssl req -nodes -new -x509 \
            -keyout recipe-api/tls/basic-private-key.key \
            -out shared/tls/basic-certificate.cert
```

此命令创建两个文件，即 basic-private-key.key（私钥）和 basic-certificate.cert（公钥）。

接下来，把在示例 1-6 中创建的 recipe-api/producer-http-basic.js 文件中的代码复制到一个名为 recipe-api/producer-https-basic.js 的新文件中，类似于<a href="#code_2-7">代码 2-7</a>。 这是一个完全使用 Node.js 构建的 HTTPS 服务器。

```js id="2-7" title="recipe-api/producer-https-basic.js"
// npm install fastify@3.2
// 注意: 使用 反向代理 更有效率
const fs = require("fs")
const server = require("fastify")({
  https: {
    // highlight-start
    key: fs.readFileSync(__dirname + "/tls/basic-private-key.key"), // 1
    cert: fs.readFileSync(__dirname + "/../shared/tls/basic-certificate.cert"),
    // highlight-end
  },
})

const HOST = process.env.HOST || "127.0.0.1"
const PORT = process.env.PORT || 4000

server.get("/recipes/:id", async (req, reply) => {
  const id = Number(req.params.id)
  if (id !== 42) {
    reply.statusCode = 404
    return { error: "not_found" }
  }
  return {
    producer_pid: process.pid,
    recipe: {
      id,
      name: "Chicken Tikka Masala",
      steps: "Throw it in a pot...",
      ingredients: [
        { id: 1, name: "Chicken", quantity: "1 lb" },
        { id: 2, name: "Sauce", quantity: "2 cups" },
      ],
    },
  }
})

server.listen(PORT, HOST, () => {
  console.log(`Producer running at https://${HOST}:${PORT}`)
})
```

1. 现在服务器已配置为使用证书并读取证书文件。

创建服务器文件后，运行服务器，然后向它发出请求。 您可以通过运行以下命令来执行此操作：

```shell
$ node recipe-api/producer-https-basic.js           # 控制台 1
$ curl --insecure https://localhost:4000/recipes/42 # 控制台 2
```

你可能注意到了命令中的 `--insecure` 标志。事实上，如果您直接在 Web 浏览器中打开 URL，您会收到证书存在问题的警告。这是自签名证书时发生的情况。

如果您要使用 Node 应用程序向该服务发出请求，该请求也会失败。Node 中的 http 和 https 模块接受一个选项参数，并且 npm 中的大多数更高级别的 HTTP 库以某种方式接受这些相同的选项。避免这些错误的一种方法是提供 rejectUnauthorized: false 标志。不幸的是，这并不比使用 HTTP 更安全，应该避免。

这一切都很重要的原因是，仅仅信任互联网上遇到的任何旧证书并不一定是安全的。相反，重要的是要知道证书是有效的。这通常是通过让一个证书“签署”另一个证书来完成的。这是一种说一个证书为另一个证书做担保的方式。例如，thomashunter.name 的证书已由另一个名为 Let's Encrypt Authority X3 的证书签名。该证书已由另一个名为 IdenTrust DST Root CA X3 的证书签名。这三个证书形成了一个信任链（见<a href="#figure_2-1">图示 2-1</a>）。

<Figure
  id="2-1"
  title="证书信任链"
  src="/books/分布式NodeJS/第2章/图片2-1_.png"
/>

链中的最高点称为根证书。该证书受到世界大部分地区的信任。事实上，它的公钥包含在现代浏览器和操作系统中。

使用自签名证书的更好方法是实际向客户端提供可信自签名证书的副本，在本例中是先前生成的 basic-certificate.cert 文件。然后可以使用 ca: certContent 选项标志传递此证书。<a href="#code_2-8">代码 2-8</a>中有一个示例。

```js id="2-8" title="web-api/consumer-https-basic.js"
// npm install fastify@3.2 node-fetch@2.6
// 注意: 使用 反向代理 更有效率

const server = require("fastify")()
const fetch = require("node-fetch")
const https = require("https")
const fs = require("fs")

const HOST = "127.0.0.1"
const PORT = process.env.PORT || 3000
const TARGET = process.env.TARGET || "localhost:4000"

const options = {
  agent: new https.Agent({
    // highlight-next-line
    ca: fs.readFileSync(__dirname + "/../shared/tls/basic-certificate.cert"),
  }),
}

server.get("/", async () => {
  const req = await fetch(`https://${TARGET}/recipes/42`, options)
  const payload = await req.json()
  return {
    consumer_pid: process.pid,
    producer_data: payload,
  }
})

server.listen(PORT, HOST, () => {
  console.log(`Consumer running at http://${HOST}:${PORT}/`)
})
```

1. 客户端闲心信任服务端所使用的特定的公匙

现在启动 web-api 服务，通过如下命令发送 HTTP 请求到该服务。

```shell
$ node web-api/consumer-https-basic.js  # terminal 1
$ curl http://localhost:3000/           # terminal 2
```

curl 命令通过 HTTP 协议与 web-api 通信，web-api 通过 HTTPS 与 recipe-api 通信。

回想一下示例 2-7，每个 HTTPS 服务器都需要访问公钥和私钥才能接收请求。还要记住，私钥永远不应该落入他人的手中。因此，为公司内的所有服务拥有一对公钥和私钥是很危险的。如果只有一个项目泄露了它的私钥，那么所有项目都会受到影响！

一种方法是为每个正在运行的服务生成一个新密钥。不幸的是，每个服务器的公钥副本都需要分发给可能想要与其通信的每个客户端，如例 2-8 所示。这将是一场维护噩梦！相反，可以模拟非自签名证书使用的方法：生成单个内部根证书，保持私钥安全，但使用它来签署每个服务的密钥集。

运行示例 2-9 中的命令来执行此操作。这些命令代表了您可能在组织内执行的操作的精简版本。 CSR 中提到的步骤将在非常私有的机器上运行，该机器仅用于生成证书。 APP 中注明的步骤将代表新应用程序执行。

```shell id="2-9" title="如何成为自己的证书颁发机构"
# Happens once for the CA
$ openssl genrsa -des3 -out ca-private-key.key 2048 // 1

$ openssl req -x509 -new -nodes -key ca-private-key.key \
              -sha256 -days 365 -out shared/tls/ca-certificate.cert // 2


# Happens for each new certificate
$ openssl genrsa -out recipe-api/tls/producer-private-key.key 2048 // 3

$ openssl req -new -key recipe-api/tls/producer-private-key.key \
  -out recipe-api/tls/producer.csr // 4

$ openssl x509 -req -in recipe-api/tls/producer.csr \
               -CA shared/tls/ca-certificate.cert \
               -CAkey ca-private-key.key -CAcreateserial \
               -out shared/tls/producer-certificate.cert -days 365 -sha256 // 5
```

1. CSR：为证书颁发机构生成私钥 ca-private-key.key。系统将提示您输入密码。
2. CSR：生成根证书 shared/tls/ca-certificate.cert（这将提供给客户端）。你会被问到很多问题，但在这个例子中它们并不重要。
3. APP：为特定服务生成私钥 producer-private-key.key。
4. APP：为同一服务创建一个 CSR producer.csr。 请务必回答本地主机的通用名称问题，但其他问题并不重要。
5. CSR：生成由 CA 签署的服务证书 producer-certificate.cert。

现在修改 web-api/consumer-https-basic.js 中的代码以加载 ca-certificate.cert 文件。 还要修改 recipe-api/producer-https-basic.js 来加载 producer-privatekey。 key 和 producer-certificate.cert 文件。 重新启动两台服务器并再次运行以下命令：

```shell
$ curl http://localhost:3000/
```

你应该得到一个成功的响应，即使 web-api 不知道 recipe-api 服务的确切证书；它从根 ca-certificate.cert 证书中获得信任。

<BorderBox title="手动密钥管理的替代方案">

这个过程最终需要做很多工作，但有一些工具可以让它变得更容易。HashiCorp Vault 有一个称为 PKI Secrets Engine 的功能。该服务提供了一个 HTTP API，除其他外，它处理证书的创建及其撤销（将特定证书标记为不再受信任，以防它被泄露）。

</BorderBox>

</Section>

<Section title="基于 HTTP 的 JSON">

到目前为止，还没有真正检查过 HTTP 请求和响应的主体。这是因为 HTTP 标准并没有规定 HTTP 消息正文中的内容。正如我之前提到的，HTTP 是许多其他协议最终都建立在其之上的协议。这就是 OSI 模型的神秘第 8 层发挥作用的地方。

今天编写的最流行的 API 是基于 HTTP 的 JSON，这种模式通常——通常被错误地——称为 REST（表示状态传输）。您在示例应用程序中来回发送的小型 JSON 有效负载是 JSON over HTTP 的示例。

简单地通过 HTTP 通过 JSON 进行通信还有很多不足之处。例如，错误是如何表示的？当然，应该利用 HTTP 错误状态代码并遵循一般语义，但实际应该为正文使用什么有效负载？表示特定内部对象的正确方法是什么
JSON？没有完全映射到 HTTP 标头的元信息（例如分页数据）呢？ JSON over HTTP 以及许多吹捧 REST 标签的 API 的问题在于，生产者和消费者之间的全部合同都存在于文档中。人类必须阅读文档并手动编写代码才能与这些有效负载进行交互。

另一个问题是每个基于 HTTP 的 JSON 服务都会以不同的方式实现。如果没有 Content-Type: application/json 标头，则在第一个和最后一个大括号之间可能发生任何事情。这通常要求特定客户端使用的每个新服务都必须编写新代码。

举一个更具体的例子，考虑分页。 “JSON over HTTP”的松散概念没有内置的方法来处理这个问题。 Stripe API 使用查询参数 ?limit=10&starting_after=20。响应正文中提供了元信息，例如 has_more 布尔属性，它让客户端知道有更多数据需要分页。另一方面，GitHub API 使用查询参数 ?per_page=10&page=3。链接响应标头中提供了有关分页的元信息。

正是由于这些原因，人们发明了在 HTTP 中表示请求和响应主体的不同标准。 JSON:API、JSON Schema 和 Open-API (Swagger) 是完全支持 JSON over HTTP 并试图将秩序带入混乱的规范。它们处理诸如描述请求和响应主体之类的概念，以及在不同程度上如何与 HTTP API 服务器交互。接下来的两节将讨论 GraphQL 和 gRPC，它们是更极端的协议更改。

第 85 页的“JSON over HTTP 基准测试”包含使用 JSON over HTTP 在两台服务器之间进行通信的基准测试。

</Section>

<Section title="序列化 POJO 的危险">

JavaScript 使得序列化域对象的内存表示变得非常容易。 通过简单地调用 JSON.stringify(obj)（大多数 HTTP 框架会自动为您执行此操作），对项目内部属性的任何重构都可能泄漏并导致 API 中断更改。 它也可能导致泄露秘密。

更好的方法是为对象添加一个安全网，以手动控制它们在 JSON 中的表示方式——一种称为编组的模式。 这可以通过使用 toJSON() 方法将可序列化数据表示为类来实现，而不是将数据存储为 POJO（Plain Ol' JavaScript Object）。

作为一个例子，这里有两种在你的代码库中表示用户对象的方法。 第一个是 POJO，第二个是带有 toJSON() 方法的类：

```js
const user1 = {
  username: "pojo",
  email: "pojo@example.org",
}

class User {
  constructor(username, email) {
    this.username = username
    this.email = email
  }
  toJSON() {
    return {
      username: this.username,
      email: this.email,
    }
  }
}
const user2 = new User("class", "class@example.org")
// ...
res.send(user1) // POJO
res.send(user2) // Class Instance
```

在这两种情况下，发送响应时，服务的使用者将收到一个 JSON 字符串，该字符串表示具有相同属性的对象：

```json
{ "username": "pojo", "email": "pojo@example.org" }
{ "username": "class", "email": "class@example.org" }
```

也许在某个时候，应用程序也被修改为开始跟踪用户的密码。 这可以通过向用户对象的实例添加新的密码属性来完成，可能通过修改创建用户实例的代码，在创建时设置密码。 或者代码库的某个黑暗角落可能正在通过调用 user.password = value 来设置密码。 这种变化可以这样表示：

```js
user1.password = user2.password = "hunter2"
// ...
res.send(user1)
res.send(user2)
```

发生这种情况时，POJO 现在正在向消费者泄露私人信息。 具有显式编组逻辑的类不会泄露这些细节：

```json
{"username":"pojo","email":"pojo@example.org","password":"hunter2"}
{"username":"class","email":"class@example.org"}
```

即使有测试检查 HTTP 响应消息中是否存在用户名和电子邮件等值，当添加了新属性（如密码）时，它们也可能不会失败。

</Section>

</Section>

<Section title="使用 GraphQL 的 API 外观">

GraphQL 是一种用于查询 API 的协议，由 Facebook 设计。它对于构建外观服务非常有用——这是一种位于多个其他服务和数据源之前的服务。 GraphQL 试图解决传统的基于 HTTP API 的 JSON 即席实现存在的几个问题。 GraphQL 特别擅长返回客户端所需的最少量数据。它还擅长使用来自多个来源的数据来混合响应有效负载，以便客户端可以在发出单个请求时获得所需的一切。

GraphQL 并未规定使用特定的底层协议。大多数实现，以及本节中使用的实现，都使用 GraphQL
HTTP，但通过 TCP 等其他协议使用它同样令人高兴。整个 GraphQL 查询使用单个字符串来描述，就像 SQL 查询一样。当实现构建在 HTTP 之上时，它们通常使用单个端点，客户端通过 POST 方法发送查询。

GraphQL 响应通常使用 JSON 提供，但同样，只要它能够表示数据层次结构，就可以使用不同的响应类型。这些示例也使用 JSON。

<Tip>

时至今日，通过 HTTP API 向公众公开 JSON 更为常见。 GraphQL API 更有可能被同一组织维护的客户端使用，例如内部使用或移动第一方应用程序。然而，这种情况开始发生变化，越来越多的公司开始公开公共 GraphQL API。

</Tip>

<Section title="GraphQL Schema">

GraphQL 模式是描述特定 GraphQL 服务器能够进行的所有交互的字符串。 它还描述了服务器可以表示的所有对象，以及这些对象的类型（例如 String 和 Int）。 这些类型基本上有两种分类； 类型要么是原始类型，要么是命名对象。 每个命名对象都需要模式中的一个条目； 不能使用没有命名和描述的对象。 创建一个新的文件名 schema.gql 并将示例 2-10 的内容输入到该文件中。

```graphql id="2-10" title="shared/graphql-schema.gql"
type Query { // 顶层查询代表
  recipe(id: ID): Recipe
  pid: Int
}

type Recipe { // Recipe类型
  id: ID!
  name: String!
  steps: String!
  ingredients: [Ingredient]!
}

type Ingredient {
  id: ID!
  name: String!
  quantity: String
}
```

1. 顶层查询
2. Recipe 类型
3. Recipe 类型有 Ingredient 类型作为子类型，存储在 ingredients 数组中

第一个条目 Query 表示消费者提供的查询的根。 在这种情况下，消费者基本上可以要求两组不同的信息。 pid 条目返回一个整数。 另一个条目 recipe 返回一个在模式文档中定义的 Recipe 类型。 这个调用在被查询时接受一个参数。 在这种情况下，模式表明通过使用名为 id 的参数调用 recipe 方法，将返回一个遵循 Recipe 模式的对象。 表 2-3 包含 GraphQL 使用的标量类型列表。

<Table id="2-3" title="GraphQL 中的变量">
  <Thead ths={["名称", "例子", "在 JSON 中的等效"]} />
  <Tbody>
    <Tr tds={["Int", "10, 0, -1", "Number"]} />
    <Tr tds={["Float", "1, -1.0", "Number"]} />
    <Tr tds={["String", "Hello, friend!\n", "String"]} />
    <Tr tds={["Boolean", "true, false", "Boolean"]} />
    <Tr tds={["ID", "'42', '975dbe93'", "String"]} />
  </Tbody>
</Table>

然后在下一个块中更详细地描述配方对象。 该块包含一个 id 属性，它是一个 ID。 默认情况下，这些字段是可空的——如果客户端请求该值而服务器没有提供该值，那么它将被强制为空。 这 ！ 字符声明服务器必须提供该字段。 配方还具有字符串（字符串）的名称和步骤属性。 最后，它有一个名为成分的属性，其中包含一个成分条目数组。 下一个块描述成分对象并包含它自己的属性。 此模式类似于迄今为止在示例应用程序中使用的响应。

</Section>

<Section title="Queries and Responses">

接下来，您将了解与此数据交互的查询可能是什么样的，以及响应负载。 GraphQL 中的查询有一个非常有用的特性，消费者可以准确地指定它正在寻找的属性。 另一个方便的功能是响应数据的格式永远不会有任何意外。 嵌套查询层次结构最终与结果数据具有相同的形状。

首先，考虑一个非常基本的示例，其中仅应从服务器检索 pid 值。 执行此操作的查询如下所示：

```graphql
{
  pid
}
```

与前一个查询匹配的示例响应负载将类似于以下内容：

```json
{
  "data": {
    "pid": 9372
  }
}
```

最外层的“信封”对象，即包含数据的对象，用于帮助区分有关响应的元信息与响应本身。 请记住，GraphQL 不依赖于 HTTP，它提供了诸如错误之类的概念，因此响应负载必须能够区分成功响应和错误（如果此查询有错误，则根中将没有 data 属性， 但会有一个错误数组）。

此外，请注意配方数据根本不显示，即使它是在 GraphQL 模式的根查询类型中定义的。 同样，这是因为查询准确地指定了应该返回哪些字段。

接下来是一个更复杂的查询。 此查询将根据其 ID 获取特定配方。 它还将获取有关属于该配方的成分的信息。 查询将如下所示：

```graphql
{
  recipe(id: 42) {
    name
    ingredients {
      name
      quantity
    }
  }
}
```

该查询声明它想要一个 id 为 42 的食谱实例。它还想要该食谱的名称，但不想要 id 或步骤属性，并且想要访问成分，特别是它们的名称和数量值。

此查询的响应负载将如下所示：

```json
{
  "data": {
    "recipe": {
      "name": "Chicken Tikka Masala",
      "ingredients": [
        { "name": "Chicken", "quantity": "1 lb" },
        { "name": "Sauce", "quantity": "2 cups" }
      ]
    }
  }
}
```

同样，请注意嵌套请求查询如何遵循与嵌套 JSON 响应相同的形状。 假设编写查询的开发人员知道架构，那么开发人员可以安全地编写任何查询并知道它是否有效，知道响应的形状，甚至知道响应中每个属性的类型。

事实上，graphql npm 包提供了一个专门用于编写和测试查询的 Web REPL。 这个界面的名字叫 GraphiQL，是“GraphQL”和“graphical”的一种玩法。

graphql 包是在 Node.js 中构建 GraphQL 服务的官方包。 它也是整个 GraphQL 的官方参考实现，因为 GraphQL 不依赖于特定的语言或平台。 以下代码示例使用了 fastify-gql 包。 这个包让 GraphQL 以一种方便的方式与 Fastify 一起工作，但它本质上是官方 graphql 包的一个包装器。

</Section>

<Section title="服务端 GraphQL">

现在您已经看到了一些示例查询及其响应，您可以编写一些代码了。 首先，根据示例 2-11 中的内容新建一个 recipe-api 服务文件。

```js id="2-11" title="recipe-api/producer-graphql.js"
// npm install fastify@3.2 fastify-gql@5.3

const server = require("fastify")()
const graphql = require("fastify-gql")
const fs = require("fs")

const schema = fs
  .readFileSync(__dirname + "/../shared/graphql-schema.gql")
  .toString() // 1
const HOST = process.env.HOST || "127.0.0.1"
const PORT = process.env.PORT || 4000

const resolvers = {
  // 2
  Query: {
    // 3
    pid: () => process.pid,
    recipe: async (_obj, { id }) => {
      if (id != 42) throw new Error(`recipe ${id} not found`)
      return {
        id,
        name: "Chicken Tikka Masala",
        steps: "Throw it in a pot...",
      }
    },
  },
  Recipe: {
    // 4
    ingredients: async (obj) => {
      return obj.id != 42
        ? []
        : [
            { id: 1, name: "Chicken", quantity: "1 lb" },
            { id: 2, name: "Sauce", quantity: "2 cups" },
          ]
    },
  },
}

server
  .register(graphql, { schema, resolvers, graphiql: true }) // 5
  .listen(PORT, HOST, () => {
    console.log(`Producer running at http://${HOST}:${PORT}/graphql`)
  })
```

1. 架构文件提供给 graphql 包。
2. 解析器对象告诉 graphql 如何构建响应。
3. Query 条目代表顶级查询。
4. 检索配方时运行配方解析器。
5. Fastify 使用 server.register() 和 fastify-gql 包； 其他框架有自己的约定。

GraphQL 代码在 server.register 行注册到 Fastify 服务器。 这最终创建了一个在 /graphql 监听传入请求的路由。 消费者稍后将向此端点发送查询。 以下对象使用 shared/graphql-schemal.gql 文件的内容、对解析器对象的引用（稍后介绍）和最终的 graphiql 标志来配置 GraphQL。 如果此标志为真，则启用前面提到的 GraphiQL 控制台。 服务运行后，可以通过 http://localhost:4000/graphiql 访问该控制台。 理想情况下，您永远不会为生产中运行的服务将该值设置为 true。

现在是时候考虑解析器对象了。 该对象在根中具有与 GraphQL 模式中描述的不同类型相关的属性。 Query 属性描述顶级查询，而 Recipe 描述 Recipe 对象。 这两个对象的每个属性都是一个异步方法（在代码中的其他地方等待的方法）。 这意味着这些方法可以返回一个承诺，它们可以是一个异步函数，或者它们可以只返回一个简单的值。 此示例中不涉及数据库，因此每个方法同步运行并返回一个简单的值。

当这些方法被调用时，GraphQL 会提供关于它们被调用的上下文的参数。 例如，考虑 resolvers.Query.recipe 方法。 在这种情况下，第一个参数是一个空对象，因为它在查询的根处被调用。 但是，第二个参数是一个对象，表示对该函数的参数。 在模式文件中，recipe() 被定义为接受一个名为 id 的参数，该参数接受一个 ID 并返回一个 Recipe 类型。 因此，在此方法中，id 作为参数提供。 它还有望返回一个遵循配方形状的对象。

在架构中，您已将配方定义为具有 id、名称、步骤和成分属性。 因此，在您返回的对象中，每个标量值都已指定。 但是，尚未定义成分属性。 当 GraphQL 代码运行时，recipe 会自动获取它。

GraphQL 强制要求来自请求的 JSON 响应与传入的查询形状相匹配。 如果 recipe() 方法中的响应对象被修改为具有一个名为 serving 的附加属性，GraphQL 将在响应发送到客户端之前自动删除该未知值。 此外，如果客户端没有请求任何已知的 id 或 name 值，它们也会从响应中删除。

一旦 GraphQL 代码运行了解析器并从 recipe() 方法调用中收到了它期望的顶级配方，并且假设客户端已经请求了成分，它现在就可以调用代码来混合这些成分值了。 这是通过调用 resolvers.Recipe.ingredients 方法来执行的。 在这种情况下，第一个参数现在包含有关父对象的信息，这里是顶级 Recipe 实例。 提供的对象包含从 recipe() 方法调用返回的所有信息（在本示例中为 id、name 和 steps 值）。 id 通常是最有用的值。 如果此应用程序由数据库支持，则 id 可用于进行数据库查询并获取相关的成分条目。 然而，这个简单的例子只使用了硬编码的值。

<Tip>

解析器对象中描述的每个方法都可以异步调用。 GraphQL 足够聪明，基本上可以并行调用它们，允许您的应用程序进行多次出站异步调用以从其他来源获取数据。 一旦最慢的请求完成，整个查询就可以完成，并且可以将响应发送给消费者。

</Tip>

</Section>

<Section title="客户端 GraphQL">

现在您已经熟悉了构建提供 GraphQL 接口的生产者，是时候看看构建消费者需要什么了。

建立消费者要简单一些。 有 npm 包可以帮助生成查询，但是与 GraphQL 服务的交互非常简单，您可以使用基本工具简单地重新构建它。

示例 2-12 创建了一个新的 web-api 消费者。 此示例最重要的部分是将要发送的查询。 它还将使用查询变量，这是 GraphQL 等效于 SQL 中的查询参数。 变量很有用，因为就像 SQL 一样，手动将字符串连接在一起以将动态数据（如用户提供的值）与静态数据（如查询代码）组合起来很危险。

```js id="2-12" title="web-api/consumer-graphql.js"
// npm install fastify@3.2 node-fetch@2.6
const server = require("fastify")()
const fetch = require("node-fetch")

const HOST = "127.0.0.1"
const PORT = process.env.PORT || 3000
const TARGET = process.env.TARGET || "localhost:4000"

const complex_query = `
  query kitchenSink ($id:ID) { // 1
    recipe(id: $id) {
      id name
      ingredients {
        name quantity
      }
    }
    pid
  }`

server.get("/", async () => {
  const req = await fetch(`http://${TARGET}/graphql`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      // 2
      query: complex_query,
      variables: { id: "42" },
    }),
  })
  return {
    consumer_pid: process.pid,
    producer_data: await req.json(),
  }
})

server.listen(PORT, HOST, () => {
  console.log(`Consumer running at http://${HOST}:${PORT}/`)
})
```

1. 这是一个接受参数的更复杂的查询。
2. 请求正文是封装了 GraphQL 查询的 JSON。

此示例发出 POST 请求并将 JSON 有效负载发送到服务器。 此有效负载包含查询和变量。 query 属性是 GraphQL 查询字符串， variables 属性包含变量名称与其值的映射。

发送的 complex_query 要求服务器支持的几乎所有数据。 它还使用更复杂的语法来指定查询中将使用哪些变量。 在这种情况下，它将查询命名为 kitchenSink，这对于调试很有用。 查询的参数在名称之后定义，在这种情况下，它声明有一个名为 $id 的变量，其类型为 ID。 然后将该变量传递给 recipe() 方法。 请求正文的 variables 属性包含一个变量。 在本节中，变量不需要以 $ 为前缀。

修改这两个文件后，运行这两个服务，然后通过运行以下命令向消费者服务发出请求：

```shell
$ node recipe-api/producer-graphql.js # terminal 1
$ node web-api/consumer-graphql.js # terminal 2
$ curl http://localhost:3000 # terminal 3
```

你将会收到如下响应:

```json
{
  "consumer_pid": 20827,
  "producer_data": {
    "data": {
      "recipe": {
        "id": "42",
        "name": "Chicken Tikka Masala",
        "ingredients": [
          { "name": "Chicken", "quantity": "1 lb" },
          { "name": "Sauce", "quantity": "2 cups" }
        ]
      },
      "pid": 20842
    }
  }
}
```

GraphQL 提供的功能比本节中列出的功能多得多。 例如，它包括一个称为突变的功能，允许客户端修改文档。 它还有一个称为订阅的功能，它允许客户端订阅和接收消息流。

第 86 页的“GraphQL 基准测试”包含使用 GraphQL 在两台服务器之间进行通信的基准测试。

</Section>

<Section title="基于 RPC 的 gRPC">

REST 之类的模式——在某种程度上是 GraphQL——试图抽象出生产者提供的底层功能，并从本质上公开由数据和 CRUD 操作驱动的 API。 尽管服务中的所有复杂性，消费者都留下了一个包含大量名词和很少动词的界面。

例如，具有 RESTful 接口的 API 可能允许消费者创建发票。 这样的操作可以通过使用 POST 方法结合名为 /invoice 的路由来执行。 但是生产者如何在创建发票时允许消费者向用户发送电子邮件？ 发票电子邮件是否应该有一个单独的端点？ 发票记录上是否应该有一个名为 email 的属性，当在创建期间设置为 true 时会触发电子邮件？ 使用 HTTP 提供的方法来表示应用程序功能通常没有完美的方法。 这时可能需要尝试一种新模式。

远程过程调用 (RPC) 就是这样一种模式。 与提供非常有限的动词列表的 HTTP 不同，RPC 基本上可以自由地支持开发人员想要的任何动词。 如果您考虑应用程序的核心，前面提到的 POST /invoice 路由最终会调用应用程序内部更深的一些代码。 代码中很可能有一个名为 create_invoice() 的关联方法。 使用 RPC，您可以将该方法（几乎以其原始形式）公开给网络，而不是通过工作来创建不同的接口。

通常，RPC 的工作方式是选择应用程序中要公开的函数，并在这些函数之间创建到某种网络接口的映射。 当然，这并不像简单地将功能暴露给网络那么简单。 这些方法需要非常严格地确定它们接受什么类型的数据以及从谁那里接受数据（就像 HTTP 端点应该那样）。

在服务之间提供网络 RPC 端点的最流行的标准之一是 Google 的 gRPC。 gRPC 通常通过 HTTP/2 提供服务。 与使用单个 HTTP 端点的 GraphQL 不同，gRPC 使用端点来确定要调用的方法。

</Section>

<Section title="协议缓冲区">

与基于 HTTP 和 GraphQL 的 JSON 不同，gRPC 通常不会通过纯文本传递消息。 相反，它使用协议缓冲区（又名 Protobufs）传输数据，这是一种表示序列化对象的二进制格式。 这种表示会导致更小的消息有效负载和更高的网络性能。 它不仅创建了更紧凑的消息，而且还减少了每条消息发送的冗余信息量。 关于 OSI 模型，可以认为 Protobufs 运行在第 8 层，而 HTTP/2 运行在第 7 层。

Protobuf 有自己的语言来描述可以在 gRPC 服务器中表示的消息。 这些文件以 .proto 结尾，让人想起 GraphQL 模式。 示例 2-13 演示了如何为 gRPC 服务定义类似的操作。

```proto id="2-13" title="shared/grpc-recipe.proto"
syntax = "proto3";
package recipe;

service RecipeService { // 1
  rpc GetRecipe(RecipeRequest) returns (Recipe) {}
  rpc GetMetaData(Empty) returns (Meta) {}
}

message Recipe {
  int32 id = 1; // 3
  string name = 2;
  string steps = 3;
  repeated Ingredient ingredients = 4; // 4
}

message Ingredient {
  int32 id = 1;
  string name = 2;
  string quantity = 3;
}

message RecipeRequest {
  int32 id = 1;
}

message Meta { // 2
  int32 pid = 2;
}

message Empty {}
```

1. 名为 RecipeService 的服务的定义。
2. Meta 类型的消息。
3. 一个名为 id 的字段，可以是 32 位整数。
4. 一个名为成分的字段中的食谱消息数组，此消息的第四个条目。

这个 recipe.proto 文件由客户端和服务器共享。 这允许两端相互通信，并能够对正在发送的消息进行解码和编码。 gRPC 定义了 RPC 方法，可以接受特定类型的消息并返回另一种类型的消息，以及服务，这些方法是对相关方法调用进行分组的方式。

注意消息类型的粒度。 GraphQL 在构建时考虑了 JSON 和 HTTP，它使用值 Int 指定数字类型，只是一个整数。 gRPC 在 C 中具有较低级别的根，更具体地使用其大小来描述整数，在本例中为 int32。 如果要在 JSON 中使用，通常没有理由限制整数的大小。 表 2-4 有更详细的常见 gRPC 数据类型列表。

<Table id="2-4" title="Common gRPC scalars">
  <Thead ths={["名称", "例子", "在 NodeJS 中的等效写法"]} />
  <Tbody>
    <Tr tds={["double", "1.1 ", "Number"]} />
    <Tr tds={["float", "1.1", "Number"]} />
    <Tr tds={["int32", "-2_147_483_648", "Number"]} />
    <Tr tds={["int64", "9_223_372_036_854_775_808", "Number"]} />
    <Tr tds={["bool", "true, false", "Boolean"]} />
    <Tr tds={["string", "'Hello, friend!\n'", "String"]} />
    <Tr tds={["bytes", "binary data", "Buffer"]} />
  </Tbody>
</Table>

重复关键字意味着一个字段可以包含多个值。 在这些情况下，值可以表示为该值类型的数组。

<Note>

还有一些其他的数字格式也可以在 gRPC 中表示。 这些包括 uint32 和 uint64、sint32 和 sint64、fixed32 和 fixed64，最后是 sfixed32 和 sfixed64。 每个对表示的数字范围、准确性以及数字在传输过程中的表示方式都有不同的限制。 @grpc/proto-loader 包可以配置为在数字不足的情况下使用字符串表示不同的值。

</Note>

关于这些消息类型的另一个有趣的部分是与每个字段关联的数值。 这些值表示字段在消息中遵循的顺序。 例如，成分消息将 id 作为第一个属性，将数量作为第三个属性。 一开始列出这些数字似乎很奇怪，但顺序非常重要。 与 JSON 在技术上没有属性顺序不同，Protocol Buffer 消息中的属性顺序非常重要，原因有两个。

第一个原因是字段名称没有与消息本身一起传输。 由于模式在客户端和服务器之间共享，因此字段的名称将是多余的。 作为对此的快速可视化，想象一下使用 JSON 传输并再次使用二进制传输的两个整数的外观。 这两条消息可能如下所示：

```text
{"id":123,"code":456}
01230456
```

如果总是发送两个数字，并且众所周知，第一个称为 id，第二个称为 code，那么将消息表示为第二行即可消除不必要的冗余。 这类似于 CSV 的工作方式：在第一行中包含列名，在后续行中包含数据。

字段顺序很重要的第二个原因是使用 Protobufs 表示的消息和 gRPC 本身被设计为向后兼容。 例如，如果 Protobufs 成分消息的 v1 包含一个 id、一个名称和一个数量字段，并且有一天会创建一个带有第四个替代字段的新 v2，那么网络上仍然使用 v1 的任何节点都可以安全地忽略 附加字段并且仍然与其他节点通信。 这在应用程序的新版本随着旧版本被逐步淘汰而缓慢发布的情况下是有益的。

gRPC 支持四种风格的消息传递，尽管这些示例只关注最基本的风格。 消息请求和响应可以是流式的，也可以是单个消息。 这些示例中使用的基本样式涉及非流式请求和响应。 但是，可以使用服务器端流式 RPC，服务器流式传输响应； 客户端流式 RPC，客户端流式传输请求； 或双向流式 RPC，其中客户端和服务器流式传输请求和响应。 处理流时，会提供一个 EventEmitter 实例，但处理单个消息时，代码将改为处理回调。

</Section>

<Section title="服务端 gRPC">

现在您已经查看了一些 Protobuf 消息和服务定义，是时候使用 Node.js 实现 gRPC 服务器了。 同样，您将从创建一个新的 recipeapi/service 开始。 创建一个类似于示例 2-14 的文件，并确保安装必要的依赖项。 以 @ 符号开头的依赖项表示 npm 注册表中的作用域包。

```js id="2-14" title="recipe-api/producer-grpc.js"
// npm install @grpc/grpc-js@1.1 @grpc/proto-loader@0.5
const grpc = require("@grpc/grpc-js")
const loader = require("@grpc/proto-loader")

const pkg_def = loader.loadSync(__dirname + "/../shared/grpc-recipe.proto") // 2
const recipe = grpc.loadPackageDefinition(pkg_def).recipe

const HOST = process.env.HOST || "127.0.0.1"
const PORT = process.env.PORT || 4000

const server = new grpc.Server()

server.addService(recipe.RecipeService.service, {
  // 2
  getMetaData: (_call, cb) => {
    // 3
    cb(null, {
      pid: process.pid,
    })
  },
  getRecipe: (call, cb) => {
    // 4
    if (call.request.id !== 42) {
      return cb(new Error(`unknown recipe ${call.request.id}`))
    }
    cb(null, {
      id: 42,
      name: "Chicken Tikka Masala",
      steps: "Throw it in a pot...",
      ingredients: [
        { id: 1, name: "Chicken", quantity: "1 lb" },
        { id: 2, name: "Sauce", quantity: "2 cups" },
      ],
    })
  },
})

server.bindAsync(
  `${HOST}:${PORT}`,
  grpc.ServerCredentials.createInsecure(), // 5
  (err, port) => {
    if (err) throw err
    server.start()
    console.log(`Producer running at http://${HOST}:${port}/`)
  },
)
```

1. 生产者需要访问 .proto 文件。 在这种情况下，它会在启动时加载和处理，从而产生很小的启动成本。
2. 定义服务时，会为对象提供反映 .proto 文件中定义的方法的属性。
3. 此方法与 .proto 定义中的 GetMetaData(Empty) 方法相关。
4. getRecipe() 方法使用请求期间传入的对象。 此对象作为 call.request 提供。
5. gRPC 可以使用 TLS 和身份验证，但在本例中它被禁用。

此服务器侦听通过端口 4000 发送到 localhost 的传入 HTTP/2 请求。与这两种方法关联的 HTTP 路由基于服务名称和方法名称。 这意味着 getMetaData() 方法在技术上位于以下 URL：

http://localhost:4000/recipe.RecipeService/GetMetaData

gRPC 包抽象了底层 HTTP/2 层，因此您通常不需要将 gRPC 服务视为基于 HTTP/2 的服务，也不必考虑路径。

</Section>

<Section title="客户端 gRPC">

现在是时候实现消费者了。 示例 2-15 是 web-api 服务的重新设计版本。 在撰写本文时，官方的 @grpc/grpc-js npm 包通过公开使用回调的方法来工作。 此代码示例使用 util.promis ify() 以便您可以使用异步函数调用方法。

```js id="2-15" title="web-api/consumer-grpc.js"
// npm install @grpc/grpc-js@1.1 @grpc/proto-loader@0.5 fastify@3.2
const util = require("util")
const grpc = require("@grpc/grpc-js")
const server = require("fastify")()
const loader = require("@grpc/proto-loader")

const pkg_def = loader.loadSync(__dirname + "/../shared/grpc-recipe.proto") // 1
const recipe = grpc.loadPackageDefinition(pkg_def).recipe

const HOST = "127.0.0.1"
const PORT = process.env.PORT || 3000
const TARGET = process.env.TARGET || "localhost:4000"

const client = new recipe.RecipeService( // 2
  TARGET,
  grpc.credentials.createInsecure(), // 3
)

const getMetaData = util.promisify(client.getMetaData.bind(client))
const getRecipe = util.promisify(client.getRecipe.bind(client))

server.get("/", async () => {
  const [meta, recipe] = await Promise.all([
    getMetaData({}), // 4
    getRecipe({ id: 42 }), // 5
  ])
  return {
    consumer_pid: process.pid,
    producer_data: meta,
    recipe,
  }
})

server.listen(PORT, HOST, () => {
  console.log(`Consumer running at http://${HOST}:${PORT}/`)
})
```

1. 就像生产者服务一样，这个服务在启动时加载 .proto 定义。
2. gRPC 客户端知道它正在连接到 recipe.RecipeService 服务。
3. 与生产者一样，安全性已被禁用。
4. GetMetaData 调用使用空消息，该消息不包含任何属性。
5. 但是，GetRecipe 调用需要一个 RecipeRequest 消息。 在这里，传入一个具有相同形状的对象。

此示例在 web-api 和 recipe-api 服务之间发送两个请求，而前面的 GraphQL 和 JSON over HTTP 示例发出一个请求。 所有需要的信息都可以在一个请求中检索到，但我觉得这个示例有助于传达 RPC 模式的核心，即在远程服务器上调用各个方法。

请注意，@grpc/grpc-js 包能够查看您的 .proto 文件并为您提供一个对象，其中包含与服务中的方法相关的方法。 在这种情况下，客户端有一个名为 getMetaData() 的方法。 这推动了 RPC 想要传达的感觉，即一个服务上的代码远程调用另一个服务上的方法，就好像这些方法存在于本地一样。

现在您已经定义了两个服务，继续运行它们并通过运行以下命令发出请求：

```shell
$ node recipe-api/producer-grpc.js # terminal 1
$ node web-api/consumer-grpc.js # terminal 2
$ curl http://localhost:3000/ # terminal 3
```

对此请求的响应应类似于以下 JSON 负载：

```json
{
  "consumer_pid": 23786,
  "producer_data": { "pid": 23766 },
  "recipe": {
    "id": 42,
    "name": "Chicken Tikka Masala",
    "steps": "Throw it in a pot...",
    "ingredients": [
      { "id": 1, "name": "Chicken", "quantity": "1 lb" },
      { "id": 2, "name": "Sauce", "quantity": "2 cups" }
    ]
  }
}
```

消费者服务将两个 gRPC 方法的结果组合在一起，但它们在生成的文档中仍然可见。 recipe 属性与 .proto 文件中的 Recipe 消息定义相关。 注意它是如何包含一个名为成分的属性的，它是一个食谱实例的数组。

第 3 章的<a href="../第3章#gRPC-基准">3.4.3 gRPC 基准</a>包含使用 gRPC 在两台服务器之间进行通信的基准测试。

<BorderBox title="Protobufs 和 gRPC 的替代品">

本节从技术上考察了两项技术。第一个是 Protocol Buffers，它是对象的二进制序列化格式，第二个是 gRPC，一个与平台无关的 RPC 模式实现。

Protobufs 有几个值得注意的替代方案。其中之一是一种称为 MessagePack 的格式。 MessagePack 是分层对象数据的二进制表示，从技术上讲，它更像是 JSON 的替代品，因为它还在其消息有效负载中包含字段名称——MessagePack 没有像 Protobufs 那样描述模式的单独文件。如果 API 已经使用 JSON，那么采用 MessagePack 会比采用 gRPC 更容易，因为不需要提前共享模式。

更接近 gRPC 和 Protobufs 的替代品是 Apache Thrift。 Thrift 也是消息的二进制表示，并使用单独的文件来定义模式和 RPC 样式的方法调用。值得一提的是，gRPC 比 Thrift 更流行一点。 JSON RPC 是另一种与平台无关的 RPC 实现。顾名思义，它不使用二进制编码。相反，有效负载和方法调用完全使用 JSON 表示。当通过 TCP 等协议异步发送时，它提供了关联请求和响应消息的机制，其中配对请求和响应的概念难以维护。

</BorderBox>

</Section>

</Section>
